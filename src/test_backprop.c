/* automatically generated by 'generate_test.py' */
void test_back_propagation()
{
    // create network
    int dims[] = {2, 3, 4, 3, 2};
    Network network = network_create(5, dims);

    // allocate variable arrays
    double **neurons = malloc(network.ndim * sizeof(double *));

    double **weights_grads = malloc(network.ndim * sizeof(double *));
    double **biases_grads = malloc(network.ndim * sizeof(double *));

    neurons[0] = calloc(sizeof(double), dims[0]);
    for (int l = 1; l < network.ndim; l++)
    {
        neurons[l] = calloc(sizeof(double), dims[l]);

        weights_grads[l] = calloc(sizeof(double), dims[l] * dims[l - 1]);
        biases_grads[l] = calloc(sizeof(double), dims[l]);
    }

    // fill network
    network.weights[1][0] = 0.30742281675338745;
    network.weights[1][1] = 0.6340786814689636;
    network.weights[1][2] = 0.4900934100151062;
    network.weights[1][3] = 0.8964447379112244;
    network.weights[1][4] = 0.455627977848053;
    network.weights[1][5] = 0.6323062777519226;
    network.weights[2][0] = 0.3488934636116028;
    network.weights[2][1] = 0.40171730518341064;
    network.weights[2][2] = 0.022325754165649414;
    network.weights[2][3] = 0.16885894536972046;
    network.weights[2][4] = 0.2938884496688843;
    network.weights[2][5] = 0.518521785736084;
    network.weights[2][6] = 0.6976675987243652;
    network.weights[2][7] = 0.800011396408081;
    network.weights[2][8] = 0.16102945804595947;
    network.weights[2][9] = 0.28226858377456665;
    network.weights[2][10] = 0.6816085577011108;
    network.weights[2][11] = 0.9151939749717712;
    network.weights[3][0] = 0.39709991216659546;
    network.weights[3][1] = 0.8741558790206909;
    network.weights[3][2] = 0.41940832138061523;
    network.weights[3][3] = 0.5529070496559143;
    network.weights[3][4] = 0.9527381062507629;
    network.weights[3][5] = 0.036164820194244385;
    network.weights[3][6] = 0.1852310299873352;
    network.weights[3][7] = 0.37341737747192383;
    network.weights[3][8] = 0.3051000237464905;
    network.weights[3][9] = 0.9320003986358643;
    network.weights[3][10] = 0.17591017484664917;
    network.weights[3][11] = 0.2698335647583008;
    network.weights[4][0] = 0.15067976713180542;
    network.weights[4][1] = 0.03171950578689575;
    network.weights[4][2] = 0.20812976360321045;
    network.weights[4][3] = 0.9297990202903748;
    network.weights[4][4] = 0.7231091856956482;
    network.weights[4][5] = 0.7423362731933594;
    network.biases[1][0] = 0.5262957811355591;
    network.biases[1][1] = 0.24365824460983276;
    network.biases[1][2] = 0.584592342376709;
    network.biases[2][0] = 0.033152639865875244;
    network.biases[2][1] = 0.13871687650680542;
    network.biases[2][2] = 0.242235004901886;
    network.biases[2][3] = 0.815468966960907;
    network.biases[3][0] = 0.793160617351532;
    network.biases[3][1] = 0.2782524824142456;
    network.biases[3][2] = 0.48195880651474;
    network.biases[4][0] = 0.8197803497314453;
    network.biases[4][1] = 0.9970665574073792;

    // fill gradients
    double *nabla_w1 = malloc(6 * sizeof(double));
    nabla_w1[0] = 0.00025686941808089614;
    nabla_w1[1] = 0.0003976424632128328;
    nabla_w1[2] = 0.0003575354639906436;
    nabla_w1[3] = 0.000553476857021451;
    nabla_w1[4] = 0.0002578126732259989;
    nabla_w1[5] = 0.0003991026314906776;
    double *nabla_w2 = malloc(12 * sizeof(double));
    nabla_w2[0] = 0.002688888693228364;
    nabla_w2[1] = 0.0026949867606163025;
    nabla_w2[2] = 0.00276937591843307;
    nabla_w2[3] = 0.0029314709827303886;
    nabla_w2[4] = 0.0029381192289292812;
    nabla_w2[5] = 0.0030192197300493717;
    nabla_w2[6] = 0.0007846312364563346;
    nabla_w2[7] = 0.0007864107028581202;
    nabla_w2[8] = 0.000808117853011936;
    nabla_w2[9] = 0.00070181954652071;
    nabla_w2[10] = 0.0007034111768007278;
    nabla_w2[11] = 0.0007228273316286504;
    double *nabla_w3 = malloc(12 * sizeof(double));
    nabla_w3[0] = 0.0045748683623969555;
    nabla_w3[1] = 0.004994615446776152;
    nabla_w3[2] = 0.005757468752563;
    nabla_w3[3] = 0.0063690245151519775;
    nabla_w3[4] = 0.005965602584183216;
    nabla_w3[5] = 0.006512950640171766;
    nabla_w3[6] = 0.007507706992328167;
    nabla_w3[7] = 0.008305172435939312;
    nabla_w3[8] = 0.008543252013623714;
    nabla_w3[9] = 0.009327101521193981;
    nabla_w3[10] = 0.010751676745712757;
    nabla_w3[11] = 0.01189371570944786;
    double *nabla_w4 = malloc(6 * sizeof(double));
    nabla_w4[0] = 0.22618679702281952;
    nabla_w4[1] = 0.1966327726840973;
    nabla_w4[2] = 0.20767273008823395;
    nabla_w4[3] = 0.06462547928094864;
    nabla_w4[4] = 0.05618138611316681;
    nabla_w4[5] = 0.05933568999171257;
    double *nabla_b1 = malloc(3 * sizeof(double));
    nabla_b1[0] = 0.0005176141276024282;
    nabla_b1[1] = 0.0007204649155028164;
    nabla_b1[2] = 0.0005195148405618966;
    double *nabla_b2 = malloc(4 * sizeof(double));
    nabla_b2[0] = 0.0035268014762550592;
    nabla_b2[1] = 0.0038449775893241167;
    nabla_b2[2] = 0.0010291384533047676;
    nabla_b2[3] = 0.0009205209207721055;
    double *nabla_b3 = malloc(3 * sizeof(double));
    nabla_b3[0] = 0.007026912644505501;
    nabla_b3[1] = 0.009163054637610912;
    nabla_b3[2] = 0.013122276403009892;
    double *nabla_b4 = malloc(2 * sizeof(double));
    nabla_b4[0] = 0.24442560970783234;
    nabla_b4[1] = 0.06983662396669388;

    // fill inputs and label
    // double *inputs = malloc(2 * sizeof(double));
    printf("reached this statement\n");
    neurons[0][0] = 0.49625658988952637;
    neurons[0][1] = 0.7682217955589294;
    printf("reached this statement after neurons\n");

    double *label = malloc(2 * sizeof(double));
    label[0] = 0.08847743272781372;
    label[1] = 0.13203048706054688;

    // run backprop

    forward(network, neurons);
    double loss = compute_loss(network.dims[network.ndim - 1], label, neurons[network.ndim - 1]);
    backward(network, label, neurons, weights_grads, biases_grads);
    // compare loss
    assert_scalar("loss", 1.131441593170166, loss);

    // compare gradients
    assert_array("nabla_w1", 6, nabla_w1, weights_grads[1]);
    assert_array("nabla_w2", 12, nabla_w2, weights_grads[2]);
    assert_array("nabla_w3", 12, nabla_w3, weights_grads[3]);
    assert_array("nabla_w4", 6, nabla_w4, weights_grads[4]);
    assert_array("nabla_b1", 3, nabla_b1, biases_grads[1]);
    assert_array("nabla_b2", 4, nabla_b2, biases_grads[2]);
    assert_array("nabla_b3", 3, nabla_b3, biases_grads[3]);
    assert_array("nabla_b4", 2, nabla_b4, biases_grads[4]);

    for (int i = 1; i < network.ndim; i++)
    {
        free(neurons[i]);
        free(weights_grads[i]);
        free(biases_grads[i]);
    }

    free(neurons);
    free(weights_grads);
    free(biases_grads);

    // free gradients
    free(nabla_w1);
    free(nabla_w2);
    free(nabla_w3);
    free(nabla_w4);
    free(nabla_b1);
    free(nabla_b2);
    free(nabla_b3);
    free(nabla_b4);

    // free inputs and labels
    free(label);

    // destroy network
    network_destroy(network);
}
